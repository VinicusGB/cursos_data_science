{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semana 4: Descoberta e preparação de dados\n",
    "\n",
    "**Video-aula:**\n",
    "<a href=\"https://www.youtube.com/watch?v=pNT304aI4uU\" target=\"_blank\">KDD e análise de dados</a> | \n",
    "<a href=\"https://www.youtube.com/watch?v=pbksL5cpeSk\" target=\"_blank\">Preparação e pré-processamento de dados -Parte I</a> | \n",
    "<a href=\"https://www.youtube.com/watch?v=8VwLb7M-5-g\" target=\"_blank\">Preparação e pré-processamento de dados - Parte II</a>\n",
    "\n",
    "KDD e AED são processos fundamentais para que o cientista de dados seja capaz de compreender o conjunto de dados que estão disponíveis e, principalmente, ser capaz de determinar os tipos de análises que são possíveis.<br>\n",
    "É por meio da Análise Exploratória que se compreende o caminho para responder às questões de um projeto de DS.\n",
    "\n",
    "Refers: CARVALHO, André Carlos Ponce de Leon Ferreira et al. Inteligência Artificial - Uma Abordagem de Aprendizado de Máquina. Disponível em: Minha Biblioteca, (2nd edição). Grupo GEN, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KDD (Knowledge Discovery in Databases)\n",
    "__KDD ou \"Processo de Descoberta de Conhecimento\"__, segundo Fayyad, Piatetsky-Shapiro e Smyth, __é um processo de várias etapas, não trivial, interativo e iterativo__, __para identificação de padrões compreensíveis, válidos, novos e potencialmente úteis__ a \n",
    "partir de conjuntos de dados;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refers: https://numpy.org/doc/stable/reference/\n",
    "\n",
    "- __“não trivial”__ diz respeito à __complexidade__ existente na __execução e manutenção__ dos processos de KDD;\n",
    "- __“interativo”__ representa a relevância de possuir um elemento que __controle__ o processo;\n",
    "- __“iterativo”__ indica a __possibilidade de repetições em qualquer uma das etapas__ do processo;\n",
    "- __“conhecimento útil”__ aponta para a __indicação__ de que o __objetivo foi alcançado__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Geralmente é __dividido em 5 fases__:\n",
    "  - __Seleção:__ consiste em __selecionar um conjunto ou subconjunto de dados__ que farão parte da análise. As __fontes de dados__ podem ser __variadas__ (planilhas, bancos de dados, data warehouses) e possuir __dados com formatos diferentes__ (estruturados, semiestruturados e não-estruturados);\n",
    "  - __Pré-Processamento:__ consiste em fazer a __verificação da qualidade dos dados__. Exceções e ruídos são removidos. Limpeza, correção, remoção de dados inconsistentes, identificação de dados ausentes, incompletos ou não íntegros são parte do processo;\n",
    "  - __Transformação:__ consiste em aplicar __técnicas__ de transformação __como: normalização, agregação, criação de novos atributos, redução e sintetização dos dados__. Busca-se identificar atributos úteis nos dados para alcançar os objetivos pretendidos;\n",
    "  - __Mineração de Dados:__ consiste na __aplicação de algoritmos__ e técnicas para __identificar padrões nos dados e verificar hipóteses__. Geralmente as descobertas podem ser descritivas ou preditivas, _com os seguintes objetivos: regressão (uma função que faça o mapeamento dos dados), clusterização (identificar um conjunto finito de categorias ou clusters), sumarização (buscar descrição compacta para subconjunto dos dados), dependências ou associações (identificar dependências significativas entre as variáveis) e divergências (identificar alterações significativas a partir dos valores medidos)_;\n",
    "  - __Interpretação:__ consiste em __avaliar o desempenho do modelo__, ocorrendo a __consolidação do conhecimento descoberto__. A validação pode ser feita baseada em análise de profissionais ou mesmo em comparação com dados coletados anteriormente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sweetviz in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: matplotlib>=3.1.3 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from sweetviz) (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from sweetviz) (1.21.2)\n",
      "Requirement already satisfied: importlib-resources>=1.2.0 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from sweetviz) (5.4.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from sweetviz) (1.7.1)\n",
      "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from sweetviz) (1.3.3)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from sweetviz) (2.11.3)\n",
      "Requirement already satisfied: tqdm>=4.43.0 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from sweetviz) (4.62.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from importlib-resources>=1.2.0->sweetviz) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from jinja2>=2.11.1->sweetviz) (2.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.3->sweetviz) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.3->sweetviz) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.3->sweetviz) (8.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.3->sweetviz) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from matplotlib>=3.1.3->sweetviz) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->sweetviz) (2021.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from tqdm>=4.43.0->sweetviz) (0.4.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.1.3->sweetviz) (1.16.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from seaborn) (1.7.1)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from seaborn) (1.3.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from seaborn) (3.4.3)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from seaborn) (1.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (8.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vinicius.barbosa\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Could not find module 'C:\\Users\\vinicius.barbosa\\Anaconda3\\lib\\site-packages\\scipy\\.libs\\libbanded5x.UGR6EUQPIWHQH7SL62IWIXB5545VDNQZ.gfortran-win_amd64.dll' (or one of its dependencies). Try using the full path with constructor syntax.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\VINICI~1.BAR\\AppData\\Local\\Temp/ipykernel_17560/1247773878.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install sweetviz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install seaborn'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Import seaborn objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mrcmod\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F401,F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F401,F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpalettes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F401,F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mrelational\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa: F401,F403\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\rcmod.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcycler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpalettes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\palettes.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexternal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhusl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdesaturate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_color_cycle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mxkcd_rgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrayons\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\seaborn\\utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;31m# Allow distributors to run custom init code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pep440\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\_distributor_init.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibs_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibs_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'*dll'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                 \u001b[0mWinDLL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mowd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Could not find module 'C:\\Users\\vinicius.barbosa\\Anaconda3\\lib\\site-packages\\scipy\\.libs\\libbanded5x.UGR6EUQPIWHQH7SL62IWIXB5545VDNQZ.gfortran-win_amd64.dll' (or one of its dependencies). Try using the full path with constructor syntax."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gerar dados aleatórios e plotar um histograma (Distribuição)\n",
    "Gerar 30 valores (1 por dia) com minutos até 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutospordia=np.random.randint(0,60,30)\n",
    "minutospordia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.histplot(minutospordia,)\n",
    "ax.set(xlabel='Minutos Por Dia', ylabel='Qtde Vezes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AED (Análise Exploratória de Dados)\n",
    "Tem como finalidade principal __examinar os dados previamente à aplicação de qualquer técnica estatística__. Desta forma o analista consegue um __entendimento básico de seus dados e das relações existentes entre as variáveis analisadas__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Na AED é muito __comum a análise descritiva__, que de forma detalhada permite ao cientista de dados __familiarizar-se com os dados, organizá-los e sintetizá-los__ de forma a __obter as informações__ necessárias do conjunto de dados __para responder as questões que o problema__ de DS está tentando resolver;\n",
    "- A AED pode ser __comparada com as três primeiras fases do KDD__, e pode ser entendida como a __primeira e importantíssima observação sobre os dados__;\n",
    "- Para realizar a análise exploratória __é determinante conhecer__ tecnicamente o que __seus dados__ representam e __como eles são classificados__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conceitos básicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantidade de variáveis:\n",
    "- __Dados unidimensionais (univariados)__ são dados nos quais você __tem apenas uma coleção de números__, por exemplo a temperatura de pessoas de uma ala (como na tabela do slide anterior), a quantidade de gols que seu time fez por jogo no campeonato ou a média de minutos diários que você usa olhando seu instagram;\n",
    "  - _Um primeiro passo inevitável é computar alguma estatística, saber o dia que gastou mais minutos no instagram, que gastou menos, a média de minutos, a soma deles_.\n",
    "- __Dados multidimensionais (multivariados)__ são dados ques possam __ter mais de uma dimensão__, por exemplo o sexo, a idade, o peso (como na tabela já vista), os gols feitos e os gols sofridos pelo seu time, ou então a quantidade de minutos no instagram e também a quantidade de posts realizados.\n",
    "  - _Em muitos casos é importante conhecer cada dimensão individualmente, mas também é necessário dispersar os dados e entender a relação entre eles, se elas existirem_.\n",
    "\n",
    "  \n",
    "**_Obs: Às vezes vai escutar que um dado é escalar (dado único, unidimensional), que representa um dado que não é um array (vetor ou matriz) ou objeto (dict)._**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tipo de variáveis:\n",
    "- **Dados qualitativos:** Dados que representam qualidades, é chamado de qualitativo, simbólico ou categórico. Os valores podem ser associados às categorias. Podem ter seus valores ordenados, mas nunca podem receber operações aritméticas.\n",
    "  - As __variáveis qualitativas__ podem ser __nominais ou ordinais__.\n",
    "    - _Variáveis nominais_: os valores _são nomes diferentes_, _carregando a menor quantidade de informação possível. Não existe relação de ordem entre seus valores_.\n",
    "      - _CPF, RG, cor dos olhos, sexo_\n",
    "    - _Variáveis ordinais_: os valores refletem uma _ordem das categorias representadas_, desta forma _operadores de comparação (maior, menor) podem ser utilizados_.\n",
    "      - _escolaridade, patente militar, classificação no campeonato_\n",
    "- **Dados quantitativos:** Dados que representam quantidades, sendo então chamado de quantitativo ou numérico. São valores numéricos, que podem ser ordenados e usados em operações aritméticas.\n",
    "  - As __variáveis quantitativas__ podem ser __contínuas ou discretas__.\n",
    "    - _Variáveis discretas_: normalmente são representadas por valores que contêm um _número finito ou infinito contável de valores_. Casos de atributos contáveis.\n",
    "      - _valores (0/1), idade, número de peças com defeito_\n",
    "    - _Variáveis contínuas_: normalmente são representadas por valores que podem assumir um _número infinito de valores_. Geralmente _resultados de medidas (por instrumento)_;\n",
    "      - _peso, tamanho, distância_\n",
    "    - _Variáveis intervalares_: valores dentro de um intervalo, sem zero absoluto.\n",
    "      - _temperatura, datas de um calendário_\n",
    "    - _Variáveis racionais_: com zero absoluto. \n",
    "      - _quantidade de vezes que uma pessoa foi ao hospital (o zero é parâmetro)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploração:\n",
    "- Uma grande quantidade de informações úteis pode ser extraída a partir do conhecimento sobre tipos de dados e, principalmente, sobre a exploração de um conjunto de dados;\n",
    "- A estatística descritiva resume de forma quantitativa as principais características de um conjunto de dados;\n",
    "- Geralmente, partir de um tipo de análise quando se tem o conhecimento sobre o tipo de dado é algo muito interessante para se identificar características dos dados;\n",
    "- Na tabela a seguir apresentamos uma sugestão de possíveis representações para cada tipo de dados.\n",
    "<table>\n",
    "    <th>Escala</th>\n",
    "    <th>Representação</th>\n",
    "    <th>Medida de Tendência Central</th>\n",
    "    <tr>\n",
    "        <td>Nominal</td>\n",
    "        <td>Barras, linhas e pizza</td>\n",
    "        <td>Moda</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Ordinal</td>\n",
    "        <td>Boxplot</td>\n",
    "        <td>Mediana</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Intervalar</td>\n",
    "        <td>Histograma e polígonos de frequência</td>\n",
    "        <td>Média</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Racional</td>\n",
    "        <td></td>\n",
    "        <td>Média Geométrica</td>\n",
    "    </tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instação das bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install sweetviz\n",
    "import sweetviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo='https://raw.githubusercontent.com/JeffSackmann/tennis_atp/master/atp_matches_2021.csv'\n",
    "dados=pd.read_csv(arquivo)\n",
    "dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gerando uma Análise Exploratória dos Dados com SWEETVIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda=sweetviz.analyze(dados)\n",
    "eda.show_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gerando uma Matriz de Correlação (de Pearson) de variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembrando que valor 1 é correlação direta perfeita, -1 é correlação negativa perfeita e valores próximos de zero indicam a falta de existência ou dificuldade de estabelecer correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.triu(np.ones_like(dados.corr(), dtype=np.bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(dados.corr(), mask=mask, square = True, annot=True, vmin=-1, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação e pré-processamento de dados\n",
    "Técnicas de pré-processamentos tem como __principal objetivo melhorar a qualidade dos dados__ e também procurar __eliminar__ elementos que podem criar um __falso resultado__ no processamento dos dados.\n",
    "Às vezes a fase de pré-processamento tem como __objetivo ajustar os dados__ para um uso mais adequado, __modelando-o para que possa ser processado__.<br>\n",
    "_Não têm regras, não têm sequência, não têm receita de bolo, é o olhar do cientista de dados, e sua experiência, que determinam o que precisa ser feito._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conteúdo básico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pré-Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Normalmente vem antes da análise exploratória__, entretanto, isso __pode ser um ciclo que se renova a cada nova fonte de dados__ que aparece, a __cada nova pergunta que se deseja responder__, a __cada novo atributo que se deseja experimentar__ no conjunto de dados.\n",
    "- Alguns chamam essa fase de processamento, muitos de pré-processamento, porque consideram que o processamento é a fase onde modelos de machine learning são testados.\n",
    "- O pré-processamento é uma fase que __antecede__ ao uso dos __modelos de machine learning__, entretanto para que ele possa ser executado com clareza e também com assertividade é de fundamental importância que se conheça o processo completo de um \n",
    "projeto de DS. __Não há como fazer__ pré-processamento __se não se sabe onde se quer chegar__, se não se conhece os modelos computacionais a \n",
    "serem testados e a que tipo de respostas se quer chegar com o projeto.\n",
    "- Importante que se __entenda o que é possível fazer de modo global__, entretanto, é fato dizer que __somente a experiência de fazer e refazer \n",
    "projetos__ é que vai tornar a fase de __pré-processamento assertiva e eficaz__.\n",
    "- Conjuntos de dados podem apresentar diferentes características, dimensões ou formatos.\n",
    "- Como vimos, __dados estruturados__ podem ser qualitativos (nominais ou ordinais) ou quantitativos (intercalar ou racional), ou ainda podemos pensar nos __dados não estruturados__ que podem ter origem nos e-mails, áudios, vídeos entre outra fontes!\n",
    "- Os __dados podem conter ruídos, imperfeições, valores incorretos ou inconsistentes, podem ser duplicados ou ausentes__;\n",
    "- Os __atributos podem ser independentes ou correlacionados__;\n",
    "- os __conjuntos de dados__ podem apresentar __poucos ou muitos objetos__, que podem ter uma pequena ou grande quantidade de atributos.\n",
    "- Por isso é tão __IMPORTANTE conhecer os tipos de dados, as grandezas__, para que seja possível __identificar as necessidades de ajustes_ aos quais os dados precisam ser submetidos.\n",
    "- Um __conjunto de técnicas podem ser aplicadas__ e elas __não têm regras, não têm sequência, não têm receita de bolo__, é o olhar do cientista de dados, e sua experiência, que determinam o que precisa ser feito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dados podem ser __oriundos de diversas fontes__, de diversos conjuntos de dados e em determinada situação __precisam ser integrados__;\n",
    "- __Imagine__ que __dados__ podem ser oriundos __de uma API__, com informações sobre investimento em marketing e seja preciso integrar com dados de vendas feitas em uma outra plataforma digital. Aspectos como:\n",
    "  - _atributos correspondentes, com nomes diferentes em bases distintas; informações correspondentes em bases numéricas diferentes ou moedas (ou idiomas) diferentes_.\n",
    "- Em muitos casos, na integração é necessário __compreender quais são os atributos necessários de cada objeto__. Lembrando sempre que __elevado número de atributos pode comprometer o desempenho dos algoritmos de machine learning__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminação Manual de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Muitas vezes, ao __observar um conjunto de dados__, fica claro que __alguns atributos podem ser eliminados manualmente__;\n",
    "- Retirar os atributos pode estar __relacionado__, por exemplo, a __anonimização de uma base__ (nome não é necessário);\n",
    "- Em __análises preditivas__, quando __um atributo não contribui__ para a estimativa de um valor, ele __é irrelevante__ para a análise e __deve ser eliminado__.\n",
    "- __Atributos__ que contém o __mesmo valor para todos os objetos__ também devem ser __eliminados__, por exemplo, o campo cidade em uma base que analisa dados de uma determinada cidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amostragem de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Muitos algoritmos de ML tem dificuldade em lidar com números grandes de objetos, levando à saturação de memória e necessidade de ampliar a escala horizontal da estrutura física__.\n",
    "- Quanto __mais dados__ são utilizados, __maior__ tende a ser __a acurácia__ do modelo e __menor__ a __eficiência__ computacional.\n",
    "- Apesar de toda evolução computacional, haverá caso em que será __necessário trabalhar com uma amostra dos dados__, de forma que ela seja __representativa o suficiente para representar o todo__ é menor que o conjunto de dados originais para evitar desempenhos ruins no processo.\n",
    "- Um exemplo de __amostra é a progressiva__, que começa com uma amostra pequena e __aumenta progressivamente__ enquanto a __acurácia continuar a melhorar__, até atingir um ponto que não há mais evolução."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dados desbalancedados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- É comum que dados de um __subconjunto de uma determinada classe apareçam com frequência maior que das demais classes__.\n",
    "  - _Exemplo: ingressos vendidos para um show são 80% de uma área e os outros estão distribuídos entre as demais áreas_.\n",
    "- Esse __desbalanceamento afeta muito o desempenho de alguns algoritmos de machine learning__, de forma que os algoritmos __favoreçam__ a classificação de novos dados na __classe majoritária__.\n",
    "- __Redefinir o tamanho__ do conjunto de dados, utilizar diferentes custos de classificação e __induzir um modelo para uma classe__ são técnicas que podem ser utilizadas.\n",
    "- Algumas situações __incluem as técnicas de classificação com apenas uma classe__, ou os __dados são treinados separadamente por classe__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpeza dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A __qualidade do modelo__ (e dos resultados) é __diretamente impactada pela qualidade dos dados__.\n",
    "  - __Dados ruidosos__ (que possuem erros ou valores que são diferentes do esperado);\n",
    "  - __Dados inconsistentes__ (que não combinam ou contradizem valores de outros do mesmo objeto);\n",
    "  - __Dados redundantes__ (atributos com valores repetidos no mesmo objeto);\n",
    "  - __Dados incompletos__ (com ausência de valores para parte dos dados);\n",
    "  - _são motivos que impactam negativamente os resultados de uma análise_.\n",
    "- Essas deficiências podem ser causadas por problemas nos equipamentos que coletam os dados, na transmissão ou armazenamento, no preenchimento manual ou até em processos de integração."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dados Incompletos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A ausência de valores em alguns atributos pode ter diferentes\n",
    "causas.\n",
    "- __Algumas técnicas__ que podem ser utilizadas:\n",
    "  - _eliminar objetos com valores ausentes_; essa alternativa normalmente é descartada quando poucos atributos do objeto têm valores ausentes.\n",
    "  - definir e _preencher manualmente_ valores para atributos com valores ausentes;\n",
    "  - _usar algum método ou heurística para automaticamente definir valores_ para atributos com valores ausentes.\n",
    "    - nesse caso é importante definir um valor onde saiba-se que era um valor ausente anteriormente;\n",
    "    - utilizar média, moda ou mediana dos valores conhecidos (cuidado com isso).\n",
    "    - definir um indutor baseado em outros atributos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dados Inconsistentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- São dados que possuem __valores conflitantes__ em seus atributos;\n",
    "- __Inconsistências__ também podem ser __reconhecidas__ quando __relações entre atributos são claramente conhecidas__ (valores correlacionados direta ou indiretamente).\n",
    "- Algoritmos simples podem verificar existência de inconsistências, em caso de conjuntos de dados não muito grandes, dados inconsistentes podem ser removidos manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dados redundantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Um objeto redundante é um objeto que é muito __semelhante a outro no mesmo conjunto de dados__.\n",
    "- Também é considerado um atributo redundante quando ele __pode ser deduzido a partir do valor__ de um ou mais atributos. Dois ou mais atributos estão correlacionados quando apresentam um perfil de variação semelhante para os diferentes objetos.\n",
    "- Dados redundantes podem __criar a falsa sensação__ de que esse perfil de __objeto é mais importante que os demais__, induzindo o modelo de análise.\n",
    "- É importante __identificar e eliminar as redundâncias__, que podem ser feitas pela eliminação dos objetos semelhantes ou pela combinação dos valores dos atributos dos objetos semelhantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dados com ruídos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dados com ruídos são __dados que contêm objetos que, aparentemente, não pertencem à distribuição__ que gerou os dados analisados.\n",
    "- Ruído pode ser __uma variância ou erro aleatório__ no valor gerado de um atributo.\n",
    "- __Um indicador__ de presença de ruído é a __existência de outliers__, que são valores que estão além dos limites aceitáveis ou são muito diferentes dos demais valores observados para o mesmo atributo, representando, por exemplo, exceções raramente vistas.\n",
    "- Existem diversas __técnicas__ de pré-processamento que podem ser aplicadas para __detecção e remoção de ruídos__:\n",
    "  - Técnicas de __encestamento__, que suavizam o valor de um atributo. Primeiro os __valores são ordenados__, depois são\n",
    "__divididos em faixas__, e esses valores são __substituídos por uma média ou mediana__.\n",
    "  - Técnicas de __agrupamento__, em que valores que __não formarem grupos__ são considerados __ruidosos ou outliers__.\n",
    "  - Técnicas de __regressão ou classificação__, que procuram determinar um valor verdadeiro para um outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformação de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Várias __técnicas de machine learning estão limitadas à manipulação de valores__ em determinados __tipos__, alguns algoritmos estão restritos a valores __numéricos__, outros a valores __qualitativos__.\n",
    "- Em várias situações, dependendo do modelo de machine learning a ser utilizado, será __necessário converter dados qualitativos a numéricos ou vice-versa__.\n",
    "- Também há de se pensar que valores __qualitativos nominais ou ordinais podem ser tratados de forma diferente__.\n",
    "  - _Redes Neurais Artificiais e Support Vector Machines lidam apenas com valores numéricos, portanto, quando um conjunto de dados a ser utilizado por essas técnicas apresenta atributos qualitativos, os valores precisam ser convertidos para numéricos_.\n",
    "- Há __situações__ em que é necessária a __transformação__ de valor __numérico em outro__ valor __numérico__.\n",
    "  - _Isso acontece quando os limites inferior e superior de valores dos atributos são muito diferentes, o que leva a uma grande variação de valores, ou ainda quando vários atributos estão em escalas diferentes_.\n",
    "  - Essa transformação é realizada para __evitar que um atributo predomine sobre outro__.\n",
    "    - Normalização por amplitude (redefinindo uma nova escala de valores com limites máximo e mínimo) e,\n",
    "    - por padronização (com definição de valor central e um valor de espelhamento para todos os atributos),\n",
    "    - também são utilizadas para normalizar dados numéricos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redução da dimensão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Dimensionalidade é o tamanho horizontal (dimensão) do seu objeto__, ou seja, a quantidade de atributos que um determinado objeto tem.\n",
    "  - Em análise de imagens, por exemplo, cada pixel representa um atributo (imagine uma imagem 1024x1024), nos estudos de genética os dados dos genes apresentam milhares de atributos também.\n",
    "- Em muitos algoritmos, __grandes quantidades de atributos inviabilizam o processo__. A __redução__ de atributos __melhora o desempenho__, reduz seu custo operacional e torna os resultados mais compreensíveis.\n",
    "- __Duas técnicas__ bastante utilizadas para __redução de atributos são: agregação e seleção de atributos__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Técnicas de redução de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Destaca-se novamente que mesmo com a evolução computacional e toda tecnologia que amplia o processamento, usando distribuição de processos e aumentando a escala horizontal de forma a ampliar o desempenho de algoritmos, __manter atributos desnecessários__ em um conjunto de dados pode\n",
    "__levar seu modelo__ a um custo de desempenho que seja __impossível de prosseguir com a análise__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Agregação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As técnicas de __agregação substituem atributos originais por novos__ atributos formados pela __combinação de grupos__.\n",
    "  - _Reduz as dimensões por combinação dos atributos_.\n",
    "- Uma das técnicas mais conhecidas é a de Análise de Componentes Principais (PCA). Há algoritmos de ML que reproduzem o PCA, entretanto, os grandes mestres do ML sempre dizem que essa não deveria ser uma técnica para reduzir a dimensionalidade.\n",
    "- O PCA descorrelaciona estatisticamente os exemplos, reduzindo a dimensionalidade do conjunto de dados original pela eliminação de redundâncias.\n",
    "- Algumas áreas (biologia, finanças, medicina, entre outros) evitam agregar atributos, pois consideram os dados originais importantes para o processo de interpretação dos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Seleção de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As técnicas de __seleção mantêm uma parte dos atributos originais e descartam os demais__ atributos.\n",
    "  - _Reduz a dimensão eliminando atributos_.\n",
    "- __Não é simples identificar__ atributos que podem ser __eliminados__, principalmente quando há uma grande quantidade de valores. Relações complexas entre atributos torna tudo mais difícil.\n",
    "- Algumas técnicas automáticas têm sido estudadas para avaliar a qualidade ou desempenho de um subconjunto de atributos, entre elas: a abordagem embutida, a abordagem baseada em filtro e a wrapper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregar base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados=pd.read_csv('https://raw.githubusercontent.com/JeffSackmann/tennis_atp/master/atp_matches_2021.csv')\n",
    "dados.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificar dados nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verificar coluna \"winner_entry\", que tem muitos valores nulos e indica como o vencedor entrou no torneio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['winner_entry'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['winner_entry'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apagar todas as linhas que o atributo \"loser_rank\" é nulo, porque são poucas ocasioes e isso pode implicar erros nos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.dropna(subset=['loser_rank'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apagar colunas que todos os valores são nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.dropna(axis=1, how= 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alterar valor dos dados nulos em uma coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['loser_entry'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['loser_entry'].fillna(value='X',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['loser_entry'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alterar mais de um atributo, com condições diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['w_ace'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['loser_ht'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.fillna(value={'w_ace':0,'loser_ht':dados['loser_ht'].mean()},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['w_ace'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['loser_ht'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usar o método ffill para projetar um dado para o registro seguinte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['minutes'][1975:1990]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['minutes'].fillna(method='ffill',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['minutes'][1975:1990]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identificar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Eliminar duplicados de uma coluna (nem sempre se quer realmente fazer isso, cuidado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.drop_duplicates(subset=['tourney_name'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['tourney_name'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos ver como fazer um deslocamento\n",
    "Vamos importar os dados das ações da Apple\n",
    "https://finance.yahoo.com/quote/AAPL/history/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL = 'https://finance.yahoo.com/quote/AAPL/history/AAPL.csv'\n",
    "dados2=pd.read_csv(\"AAPL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados2['close_ontem']=dados2['Close'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nova coluna com a porcentagem de alteração de um dia para o outro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados2['alteracao %']=((dados2['Close']/dados2['close_ontem'])-1)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados2.dropna(subset=['alteracao %'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados2.describe(include= 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformar dados categóricos (qualitativos) em dados numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados=pd.read_csv('https://raw.githubusercontent.com/JeffSackmann/tennis_atp/master/atp_matches_2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['winner_ioc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['winner_ioc'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Veja a documentação do scikit-learn sobre preprocessing!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paises=dados['winner_ioc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lencoder = LabelEncoder()\n",
    "paises_numeros = lencoder.fit_transform(paises)\n",
    "paises_numeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paises.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['paises_numeros']=paises_numeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Qual é a última (e quinta) fase do KDD, quando é atingido o nível do conhecimento? \n",
    "\n",
    "- Seleção.\n",
    "- **Correta:** Interpretação.\n",
    "- Pré-Processamento.\n",
    "- Transformação.\n",
    "- Data Mining. \n",
    "\n",
    "**Comentário da resposta:** Você acertou! Essa é a alternativa correta. A interpretação é a quinta e última fase do KDD. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Quando há um conjunto de dados que tem atributos com valores ausentes, categorizamos esses dados como: \n",
    "- inconsistentes.\n",
    "- **Correta:** incompletos. \n",
    "- redundantes.\n",
    "- desbalanceados.\n",
    "- ruidosos.\n",
    "\n",
    "**Comentário da resposta:** Você acertou! Essa é a alternativa correta. Os dados incompletos são os que têm atributos com valores ausentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Qual o método pode ser utilizado na função fillna do Pandas, para projetar dados para o próximo registro quando esse estiver com valor nulo? \n",
    "- unique.\n",
    "- **Correta:** ffill. \n",
    "- describe.\n",
    "- drop.\n",
    "- dropna.\n",
    "\n",
    "**Comentário da resposta:** Você acertou! Essa é a alternativa correta. O método ffill é usado para projetar dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef796e1e7024433d19305a7ffeb65115dd8f1e6a355f1f9a5c3ca9ca67053e84"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
