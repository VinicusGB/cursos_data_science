{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corretor Ortográfico: Aplicando técnicas de NLP\n",
    "__Professor:__ Thiago G. Santos<br>\n",
    "__Disponível:__ <a href=\"https://cursos.alura.com.br/course/nlp-corretor-ortografico\" target=blank>ALURA</a><br>\n",
    "__Conteúdo:__<br>\n",
    "- Aprenda conceitos fundamentais do processamento de linguagem natural.\n",
    "- Saiba o que está por trás dos corretores ortográficos (spell checker).\n",
    "- Crie um corretor de palavras do zero, utilizando Python.\n",
    "- Utilize o NLTK uma das principais bibliotecas Python para NLP.\n",
    "- Aprenda o que são tokens e como utilizar NLTK para realizar a fragmentação de um texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Explorando um projeto de NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorando o problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando um corpus textual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\nimagem \\n\\nTemos a seguinte classe que representa um usuário no nosso sistema:\\n\\njava\\n\\nPara salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\\n\\njava \\n\\nSuponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/artigos.txt\",\"r\",encoding=\"utf8\") as f:\n",
    "    artigos = f.read()\n",
    "\n",
    "artigos[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uma forma de verificar o enconding \n",
    "#open(\"data/artigos.txt\",\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CORPUS = Conjunto de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2605046"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(artigos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"Olá\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá,', 'tudo', 'bem?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto_exemplo = \"Olá, tudo bem?\"\n",
    "tokens = texto_exemplo.split()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOKEN = Cada elemento do meu conjunto de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício: Token - O que são?\n",
    "Vimos em aula o que é o processo de tokenização e como aplicá-lo em uma string.\n",
    "Em NLP, o que são os tokens gerados neste processo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Token é uma sequência de caracteres separados por um limitador. Esse limitador é sempre o espaço em branco.<br>\n",
    "__b) Token é uma sequência de caracteres, separados por um limitador, que pode ser um espaço em branco, pontuação ou quebra de linhas, por exemplo.__<br>\n",
    "_Parabéns, isso mesmo! Os tokens não necessariamente são apenas palavras, podem ser uma sequência de caracteres alfanuméricos, alfabéticos com pontuações, etc._<br>\n",
    "c) Tokens são palavras advindas do processo de tokenização de uma frase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. Utilizando NLTK para tokenizar um texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refinando a tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vinicius.barbosa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando as bibliotecas\n",
    "# !conda install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá', ',', 'tudo', 'bem', '?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavras_separadas = nltk.tokenize.word_tokenize(texto_exemplo)\n",
    "palavras_separadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercicio: Token - separando uma frase\n",
    "Nesta aula discutimos sobre o processo de tokenizar uma frase, ou seja, dividi-la em pequenos pedaços. Vimos que há algumas formas de realizar esse processo, uma delas com o split() e a outra utilizando os métodos tokenize da biblioteca NLTK. Levando em consideração o trecho de código abaixo, responda:\n",
    "\n",
    "import nltk\n",
    "texto_exemplo = \"Olá, tudo bem?\"\n",
    "palavras_separadas = nltk.tokenize.word_tokenize(texto_exemplo)\n",
    "print(palavras_separadas)COPIAR CÓDIGO\n",
    "Qual alternativa apresenta corretamente a saída da função print?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "a) ['Olá', 'tudo', 'bem']<br>\n",
    "__b) ['Olá', ',', 'tudo', 'bem', '?']__<br>\n",
    "_Parabéns, isso mesmo! Quando usamos o word_tokenize() não separamos os tokens levando em conta apenas os espaços, como no split(). É considerada também a separação entre as pontuações.__<br>\n",
    "c) ['Olá,', 'tudo', 'bem?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando palavras de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(palavras_separadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_palavras(lista_tokens):\n",
    "    lista_palavras = []\n",
    "    for token in lista_tokens:\n",
    "        if token.isalpha():\n",
    "            lista_palavras.append(token)\n",
    "    return lista_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá', 'tudo', 'bem']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separa_palavras(palavras_separadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contando palavras do Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A quantidade de tokens é: 515827\n"
     ]
    }
   ],
   "source": [
    "#Criando os tokens\n",
    "lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
    "print(f\" A quantidade de tokens é: {len(lista_tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantidade de palavras é: 403031\n"
     ]
    }
   ],
   "source": [
    "#Linmpoando os tokens para apenas palavras\n",
    "lista_palavras = separa_palavras(lista_tokens)\n",
    "print(f\"A quantidade de palavras é: {len(lista_palavras)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagem', 'Temos', 'a', 'seguinte', 'classe']\n"
     ]
    }
   ],
   "source": [
    "print(lista_palavras[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para normalizar nosso texto\n",
    "def normalizacao(lista_palavras):\n",
    "    lista_normalizada = []\n",
    "    for palavra in lista_palavras:\n",
    "        lista_normalizada.append(palavra.lower())\n",
    "    return lista_normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imagem', 'temos', 'a', 'seguinte', 'classe']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_normalizada = normalizacao(lista_palavras)\n",
    "lista_normalizada[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantidade de palavras normalizadas é: 403031\n"
     ]
    }
   ],
   "source": [
    "print(f\"A quantidade de palavras normalizadas é: {len(lista_normalizada)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantidade de palavras normalizadas e sem repetição são: 18464\n"
     ]
    }
   ],
   "source": [
    "# Função set() retorna um conjunto de dados sem repetição\n",
    "print(f\"A quantidade de palavras normalizadas e sem repetição são: {len(set(lista_normalizada))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício: Separando apenas palavras\n",
    "Vimos que é necessário criar uma lista apenas com as palavras do nosso corpus para “treinar” o corretor ortográfico. Como no processo de tokenização geramos uma lista de sequência de caracteres e não apenas palavras, é preciso gerá-la.\n",
    "\n",
    "def separa_palavras(lista_tokens):\n",
    "    lista_palavras = []\n",
    "    for token in lista_tokens:\n",
    "        if token.isalpha():\n",
    "            lista_palavras.append(token)\n",
    "    return lista_palavrasCOPIAR CÓDIGO\n",
    "Considerando o trecho de código acima, assinale a alternativa com a devida entrada lista_tokens da função separa_palavras() para gerar a seguinte lista de saída:\n",
    "\n",
    "['Olá', 'tudo', 'bem']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "a) Para gerar ['Olá', 'tudo', 'bem'] a entrada deve ser ['Olá', ',', 'tudo12', 'bem', '?']<br>\n",
    "__b) Para gerar ['Olá', 'tudo', 'bem'] a entrada deve ser ['Olá', ',', 'tudo', 'bem', '?']__<br>\n",
    "_Parabéns, isso mesmo! A função isalpha() verifica se todos os caracteres do token são alfabéticos, se o retorno for verdadeiro ele é armazenado na variável lista_palavras._<br>\n",
    "c) Para gerar ['Olá', 'tudo', 'bem'] a entrada deve ser ['Olá,', 'tudo', 'bem?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Desenvolvendo e testando o corretor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detalhando o corretor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fatiando strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('l', 'gica')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = \"lgica\"\n",
    "(lista[:1],lista[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', 'lgica'), ('l', 'gica'), ('lg', 'ica'), ('lgi', 'ca'), ('lgic', 'a'), ('lgica', '')]\n"
     ]
    }
   ],
   "source": [
    "palavra_exemplo = \"lgica\"\n",
    "def gerador_palavras(palavras):\n",
    "    fatias = []\n",
    "    for i in range(len(palavras)+1):\n",
    "        fatias.append((lista[:i],lista[i:]))\n",
    "    print(fatias)\n",
    "    #palavras_geradas = insere_letras(fatias)\n",
    "    #return palavras_geradas\n",
    "\n",
    "gerador_palavras(palavra_exemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insere_letras(fatias):\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operação de inserção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algica', 'blgica', 'clgica', 'dlgica', 'elgica', 'flgica', 'glgica', 'hlgica', 'ilgica', 'jlgica', 'klgica', 'llgica', 'mlgica', 'nlgica', 'olgica', 'plgica', 'qlgica', 'rlgica', 'slgica', 'tlgica', 'ulgica', 'vlgica', 'wlgica', 'xlgica', 'ylgica', 'zlgica', 'álgica', 'âlgica', 'àlgica', 'ãlgica', 'élgica', 'èlgica', 'êlgica', 'ílgica', 'ìlgica', 'îlgica', 'ólgica', 'òlgica', 'õlgica', 'ôlgica', 'úlgica', 'ùlgica', 'ûlgica', 'çlgica', 'lagica', 'lbgica', 'lcgica', 'ldgica', 'legica', 'lfgica', 'lggica', 'lhgica', 'ligica', 'ljgica', 'lkgica', 'llgica', 'lmgica', 'lngica', 'logica', 'lpgica', 'lqgica', 'lrgica', 'lsgica', 'ltgica', 'lugica', 'lvgica', 'lwgica', 'lxgica', 'lygica', 'lzgica', 'lágica', 'lâgica', 'làgica', 'lãgica', 'légica', 'lègica', 'lêgica', 'lígica', 'lìgica', 'lîgica', 'lógica', 'lògica', 'lõgica', 'lôgica', 'lúgica', 'lùgica', 'lûgica', 'lçgica', 'lgaica', 'lgbica', 'lgcica', 'lgdica', 'lgeica', 'lgfica', 'lggica', 'lghica', 'lgiica', 'lgjica', 'lgkica', 'lglica', 'lgmica', 'lgnica', 'lgoica', 'lgpica', 'lgqica', 'lgrica', 'lgsica', 'lgtica', 'lguica', 'lgvica', 'lgwica', 'lgxica', 'lgyica', 'lgzica', 'lgáica', 'lgâica', 'lgàica', 'lgãica', 'lgéica', 'lgèica', 'lgêica', 'lgíica', 'lgìica', 'lgîica', 'lgóica', 'lgòica', 'lgõica', 'lgôica', 'lgúica', 'lgùica', 'lgûica', 'lgçica', 'lgiaca', 'lgibca', 'lgicca', 'lgidca', 'lgieca', 'lgifca', 'lgigca', 'lgihca', 'lgiica', 'lgijca', 'lgikca', 'lgilca', 'lgimca', 'lginca', 'lgioca', 'lgipca', 'lgiqca', 'lgirca', 'lgisca', 'lgitca', 'lgiuca', 'lgivca', 'lgiwca', 'lgixca', 'lgiyca', 'lgizca', 'lgiáca', 'lgiâca', 'lgiàca', 'lgiãca', 'lgiéca', 'lgièca', 'lgiêca', 'lgiíca', 'lgiìca', 'lgiîca', 'lgióca', 'lgiòca', 'lgiõca', 'lgiôca', 'lgiúca', 'lgiùca', 'lgiûca', 'lgiçca', 'lgicaa', 'lgicba', 'lgicca', 'lgicda', 'lgicea', 'lgicfa', 'lgicga', 'lgicha', 'lgicia', 'lgicja', 'lgicka', 'lgicla', 'lgicma', 'lgicna', 'lgicoa', 'lgicpa', 'lgicqa', 'lgicra', 'lgicsa', 'lgicta', 'lgicua', 'lgicva', 'lgicwa', 'lgicxa', 'lgicya', 'lgicza', 'lgicáa', 'lgicâa', 'lgicàa', 'lgicãa', 'lgicéa', 'lgicèa', 'lgicêa', 'lgicía', 'lgicìa', 'lgicîa', 'lgicóa', 'lgicòa', 'lgicõa', 'lgicôa', 'lgicúa', 'lgicùa', 'lgicûa', 'lgicça', 'lgicaa', 'lgicab', 'lgicac', 'lgicad', 'lgicae', 'lgicaf', 'lgicag', 'lgicah', 'lgicai', 'lgicaj', 'lgicak', 'lgical', 'lgicam', 'lgican', 'lgicao', 'lgicap', 'lgicaq', 'lgicar', 'lgicas', 'lgicat', 'lgicau', 'lgicav', 'lgicaw', 'lgicax', 'lgicay', 'lgicaz', 'lgicaá', 'lgicaâ', 'lgicaà', 'lgicaã', 'lgicaé', 'lgicaè', 'lgicaê', 'lgicaí', 'lgicaì', 'lgicaî', 'lgicaó', 'lgicaò', 'lgicaõ', 'lgicaô', 'lgicaú', 'lgicaù', 'lgicaû', 'lgicaç']\n"
     ]
    }
   ],
   "source": [
    "palavra_exemplo = \"lgica\"\n",
    "\n",
    "def insere_letras(fatias):\n",
    "    novas_palavras =  []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzáâàãéèêíìîóòõôúùûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras\n",
    "\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i],palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
    "print(palavras_geradas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício: Generalizando o corretor\n",
    "Nesta aula vimos que podemos construir algoritmos capazes de corrigir os erros de digitação de um usuário. Para simplificar o desenvolvimento desses algoritmos, “fatiamos” nossa palavra em dois lados (esquerdo e direito).\n",
    "\n",
    "Qual foi a vantagem em fazer a divisão da string em lado esquerdo e direito?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) A vantagem em se fazer a divisão é trabalhar com os lados separadamente, realizando as operações necessárias em cada um deles, de forma a gerar uma nova palavra que pode ser a correta.<br>\n",
    "_Aqui estamos afirmando que cada lado gera uma nova palavra, porém não é verdade. A concatenação dos lados mais a operação necessária para o método em desenvolvimento gera uma única palavra._<br>\n",
    "b) A vantagem em se fazer a divisão é trabalhar com os lados separadamente, realizando as operações necessárias em cada um deles, e então concatená-los para gerar a nova palavra. Apenas o método de inserção de caracteres irá se beneficiar desta divisão.<br>\n",
    "_Na realidade todos os métodos estudados neste curso irão se beneficiar desta divisão, pois conseguimos pensar nos métodos quase como se fossem operações matemáticas, o que facilita a construção dos algoritmos._<br>\n",
    "__c) A vantagem em se fazer a divisão é trabalhar com os lados separadamente, realizando as operações necessárias em cada um dos lados e então concatená-los para gerar a nova palavra.<br>__\n",
    "_Parabéns, realizar essa divisão é útil para todos os métodos que vamos estudar, facilita o desenvolvimento dos algoritmos fazendo com que sejam pensados quase como operações matemáticas._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construíndo a função corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavra_correta = max(palavras_geradas,key=probabilidade)\n",
    "    return palavra_correta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidade das palavras geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('de', 15502),\n",
       " ('o', 14056),\n",
       " ('que', 12230),\n",
       " ('a', 11099),\n",
       " ('e', 10501),\n",
       " ('para', 7710),\n",
       " ('um', 6367),\n",
       " ('é', 5899),\n",
       " ('uma', 5220),\n",
       " ('do', 5124)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#frequencia_palavra/total_de_palavras\n",
    "\n",
    "frequencia = nltk.FreqDist(lista_normalizada)\n",
    "frequencia.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencia[\"lógica\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403031"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_palavras = len(lista_normalizada)\n",
    "total_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilidade(palavra_gerada):\n",
    "    return frequencia[palavra_gerada]/total_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00023819507680550628"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilidade(\"lógica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilidade(\"logica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corretor(palavra_exemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício: Adicionando uma nova letra\n",
    "Quando digitamos, um erro muito comum de acontecer é esquecermos uma das letras de uma palavra. Na aula, utilizamos como exemplo \"lgica\", quando queríamos ter digitado \"lógica\".\n",
    "\n",
    "Qual função devemos utilizar para que o corretor funcione, gerando a palavra esperada, ou seja, \"lógica\"?\n",
    "\n",
    "OBS: A entrada da função é uma lista com as fatias da palavra a ser corrigida em lados esquerdo e direito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "a) def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras<br>\n",
    "__b) def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzáâàãéêèẽíîìĩóôõòúûùũç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras<br>__\n",
    "_Parabéns, aqui geramos um conjunto de novas palavras, das quais uma será a correta (“lógica”), pois estamos adicionando as letras com e sem acentos entre os lados esquerdo e direito._<br>\n",
    "c) def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzáâàãéêèẽíîìĩóôõòúûùũç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + D)\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. Avaliando a qualidade do corretor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('podemos', 'pyodemos'),\n",
       " ('esse', 'esje'),\n",
       " ('já', 'jrá'),\n",
       " ('nosso', 'nossov'),\n",
       " ('são', 'sãêo'),\n",
       " ('dos', 'dosa'),\n",
       " ('muito', 'muifo'),\n",
       " ('imagem', 'iômagem'),\n",
       " ('sua', 'ósua'),\n",
       " ('também', 'tambéùm'),\n",
       " ('ele', 'eme'),\n",
       " ('fazer', 'èazer'),\n",
       " ('temos', 'temfs'),\n",
       " ('essa', 'eàssa'),\n",
       " ('quando', 'quaôdo'),\n",
       " ('vamos', 'vamvos'),\n",
       " ('sobre', 'hsobre'),\n",
       " ('java', 'sjava'),\n",
       " ('das', 'daõs'),\n",
       " ('agora', 'agorah'),\n",
       " ('está', 'eòtá'),\n",
       " ('cada', 'céda'),\n",
       " ('mesmo', 'zmesmo'),\n",
       " ('nos', 'noâ'),\n",
       " ('forma', 'fobma'),\n",
       " ('seja', 'sejéa'),\n",
       " ('então', 'enêão'),\n",
       " ('criar', 'èriar'),\n",
       " ('código', 'cóeigo'),\n",
       " ('caso', 'casío'),\n",
       " ('exemplo', 'áexemplo'),\n",
       " ('tem', 'tĩem'),\n",
       " ('usuário', 'usuárôio'),\n",
       " ('dados', 'dfados'),\n",
       " ('python', 'pgthon'),\n",
       " ('nossa', 'nossah'),\n",
       " ('além', 'alémè'),\n",
       " ('assim', 'asõim'),\n",
       " ('ter', 'teb'),\n",
       " ('até', 'atĩ'),\n",
       " ('bem', 'âem'),\n",
       " ('design', 'desigen'),\n",
       " ('trabalho', 'trabalàho'),\n",
       " ('foi', 'foo'),\n",
       " ('apenas', 'apenaũ'),\n",
       " ('empresa', 'empresà'),\n",
       " ('valor', 'valíor'),\n",
       " ('será', 'serr'),\n",
       " ('entre', 'entke'),\n",
       " ('método', 'méqodo'),\n",
       " ('precisamos', 'precisamops'),\n",
       " ('ainda', 'ainàa'),\n",
       " ('vai', 'van'),\n",
       " ('conteúdo', 'ûconteúdo'),\n",
       " ('seus', 'çeus'),\n",
       " ('eu', 'eû'),\n",
       " ('todos', 'todtos'),\n",
       " ('tempo', 'temeo'),\n",
       " ('sempre', 'semre'),\n",
       " ('qual', 'quakl'),\n",
       " ('ela', 'elaá'),\n",
       " ('só', 'síó'),\n",
       " ('utilizar', 'utiqizar'),\n",
       " ('projeto', 'prhojeto'),\n",
       " ('site', 'siàe'),\n",
       " ('sem', 'seém'),\n",
       " ('pelo', 'peln'),\n",
       " ('alura', 'aléra'),\n",
       " ('dia', 'tdia'),\n",
       " ('tudo', 'tuúo'),\n",
       " ('podemos', 'kpodemos'),\n",
       " ('esse', 'eẽsse'),\n",
       " ('já', 'jé'),\n",
       " ('nosso', 'nçosso'),\n",
       " ('são', 'sãô'),\n",
       " ('dos', 'odos'),\n",
       " ('muito', 'tuito'),\n",
       " ('imagem', 'imõgem'),\n",
       " ('sua', 'siua'),\n",
       " ('também', 'tamvbém'),\n",
       " ('ele', 'elpe'),\n",
       " ('fazer', 'façzer'),\n",
       " ('temos', 'teos'),\n",
       " ('essa', 'eũsa'),\n",
       " ('quando', 'quaìdo'),\n",
       " ('vamos', 'vjmos'),\n",
       " ('sobre', 'sxobre'),\n",
       " ('java', 'jkva'),\n",
       " ('das', 'dms'),\n",
       " ('agora', 'agtora'),\n",
       " ('está', 'esútá'),\n",
       " ('cada', 'cava'),\n",
       " ('mesmo', 'medmo'),\n",
       " ('nos', 'ános'),\n",
       " ('forma', 'forûa'),\n",
       " ('seja', 'smeja'),\n",
       " ('então', 'enjtão'),\n",
       " ('criar', 'criôar'),\n",
       " ('código', 'cóàigo'),\n",
       " ('caso', 'èaso'),\n",
       " ('exemplo', 'exbemplo'),\n",
       " ('tem', 'túem'),\n",
       " ('usuário', 'usuárin'),\n",
       " ('dados', 'daáos'),\n",
       " ('python', 'pythoçn'),\n",
       " ('nossa', 'nossk'),\n",
       " ('além', 'âlém'),\n",
       " ('assim', 'aóssim'),\n",
       " ('ter', 'tãer'),\n",
       " ('até', 'vté'),\n",
       " ('bem', 'búm'),\n",
       " ('design', 'íesign'),\n",
       " ('trabalho', 'trabèalho'),\n",
       " ('foi', 'kfoi'),\n",
       " ('apenas', 'aapenas'),\n",
       " ('empresa', 'pmpresa'),\n",
       " ('valor', 'valoqr'),\n",
       " ('será', 'sçerá'),\n",
       " ('entre', 'entró'),\n",
       " ('método', 'nétodo'),\n",
       " ('precisamos', 'prefcisamos'),\n",
       " ('ainda', 'sainda'),\n",
       " ('vai', 'uai'),\n",
       " ('conteúdo', 'cĩonteúdo'),\n",
       " ('seus', 'sâus'),\n",
       " ('eu', 'ìeu'),\n",
       " ('todos', 'todás'),\n",
       " ('tempo', 'utempo'),\n",
       " ('sempre', 'sempce'),\n",
       " ('qual', 'fual'),\n",
       " ('ela', 'elal'),\n",
       " ('só', 'skó'),\n",
       " ('utilizar', 'utilĩzar'),\n",
       " ('projeto', 'proójeto'),\n",
       " ('site', 'isite'),\n",
       " ('sem', 'secm'),\n",
       " ('pelo', 'pẽlo'),\n",
       " ('alura', 'aluéa'),\n",
       " ('dia', 'dil'),\n",
       " ('tudo', 'tudy'),\n",
       " ('ela', 'qelay'),\n",
       " ('só', 'sód'),\n",
       " ('utilizar', 'dtilizacr'),\n",
       " ('projeto', 'bprojõto'),\n",
       " ('site', 'ysiteo'),\n",
       " ('sem', 'sõêm'),\n",
       " ('pelo', 'peàli'),\n",
       " ('alura', 'asuraó'),\n",
       " ('dia', 'deiìa'),\n",
       " ('tudo', 'tuĩdoì'),\n",
       " ('ela', 'eúaa'),\n",
       " ('só', 'ró'),\n",
       " ('utilizar', 'utilizẽaçr'),\n",
       " ('projeto', 'prêjetó'),\n",
       " ('site', 'sqiqte'),\n",
       " ('sem', 'sũexm'),\n",
       " ('pelo', 'pçlxo'),\n",
       " ('alura', 'uluraa'),\n",
       " ('dia', 'dĩaz'),\n",
       " ('tudo', 'kzudo'),\n",
       " ('corretor', 'correptor'),\n",
       " ('tática', 'trtica'),\n",
       " ('empoderamento', 'ewpoderamento'),\n",
       " ('linux', 'lifux'),\n",
       " ('cachorro', 'cachoçro'),\n",
       " ('gato', 'îgato'),\n",
       " ('cavalo', 'cakvalo'),\n",
       " ('relógio', 'relógiuo'),\n",
       " ('canela', 'canelac'),\n",
       " ('tênis', 'tênisy'),\n",
       " ('ansiosa', 'anciosa'),\n",
       " ('ansiosa', 'ancciosa'),\n",
       " ('ansiosa', 'ansioa'),\n",
       " ('empoderamento', 'empoderamento'),\n",
       " ('asterisco', 'asterístico'),\n",
       " ('gratuito', 'gratuíto'),\n",
       " ('entretido', 'entertido'),\n",
       " ('ritmo', 'ritimo'),\n",
       " ('idiota', 'indiota'),\n",
       " ('tomara', 'tomare'),\n",
       " ('seja', 'seje'),\n",
       " ('prevalecer', 'provalecer'),\n",
       " ('esteja', 'esteje'),\n",
       " ('mendigo', 'mindigo'),\n",
       " ('cérebro', 'célebro'),\n",
       " ('perturbar', 'pertubar')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cria_dados_teste(nome_arquivo):\n",
    "    lista_palavras_teste = []\n",
    "    f = open(nome_arquivo, \"r\")\n",
    "    for linha in f:\n",
    "        correta, errada = linha.split()\n",
    "        lista_palavras_teste.append((correta, errada))\n",
    "    f.close()\n",
    "    return lista_palavras_teste\n",
    "\n",
    "lista_teste = cria_dados_teste(\"Data/palavras.txt\")\n",
    "lista_teste\n",
    "\n",
    "#def avaliador(testes):\n",
    "#    print(\"taxa de acerto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando o corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A taxa de acerto é: 1.08% no total 186 palavras.\n"
     ]
    }
   ],
   "source": [
    "def avaliador(testes):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "    taxa_acerto = round(acertou*100 / numero_palavras, 2)\n",
    "    print(f\"A taxa de acerto é: {taxa_acerto}% no total {numero_palavras} palavras.\")\n",
    "\n",
    "avaliador(lista_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício: Avaliando o corretor\n",
    "Para acompanharmos a evolução do desenvolvimento do corretor, precisamos medir a qualidade (taxa de acerto). Portanto desenvolvemos em aula a função avaliador(), que calcula a taxa de acerto do nosso corretor.\n",
    "\n",
    "Agora chegou a hora de praticar: qual das alternativas implementa a função avaliador() de forma a calcular corretamente a taxa de acerto do corretor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a) def avaliador(testes):__\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "    taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
    "    print(f\"{taxa_acerto}% de {numero_palavras} palavras\")\n",
    "\n",
    "avaliador(lista_teste)\n",
    "\n",
    "_Parabéns, esta função incrementa corretamente, e o contador acertou calcula a taxa de maneira correta._\n",
    "<br>\n",
    "b)\n",
    "def avaliador(testes):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou -= 1\n",
    "    taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
    "    print(f\"{taxa_acerto}% de {numero_palavras} palavras\")\n",
    "\n",
    "avaliador(lista_teste)\n",
    "<br>\n",
    "c)\n",
    "def avaliador(testes):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        acertou += 1\n",
    "    taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
    "    print(f\"{taxa_acerto}% de {numero_palavras} palavras\")\n",
    "\n",
    "avaliador(lista_teste)\n",
    "\n",
    "Parabéns, você acertou!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. Incrementando o corretor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operação de delete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementando o delete de caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deletando_caractereres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(E + D[1:])\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gerador_palavras()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercícios: Deletando caracteres\n",
    "Outro erro de digitação ocorre quando acrescenta-se um caractere a mais na palavra; o exemplo utilizado no curso foi “lóigica”. Repare que a letra “i” é próxima do “o” no teclado, então, esbarrar no “i” no momento de digitar “lógica” pode gerar esse tipo de erro. Analise o trecho de código e responda:\n",
    "\n",
    "def deletando_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(SEU_CÓDIGO)\n",
    "    return novas_palavrasCOPIAR CÓDIGO\n",
    "OBS: A entrada da função é uma lista com as fatias da palavra a ser corrigida em lados esquerdo e direito.\n",
    "\n",
    "Dentre as opções abaixo, qual deve substituir SEU_CÓDIGO para corrigir o erro que está sendo discutido na questão?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Como digitamos um caractere a mais, precisamos deletá-lo. Para realizar esta operação devemos substituir SEU_CÓDIGO por E + D - D[0].<br>\n",
    "b) Como digitamos um caractere a mais, precisamos deletá-lo. Para realizar esta operação devemos substituir SEU_CÓDIGO por E + D[2:].<br>\n",
    "__c) Como digitamos um caractere a mais, precisamos deletá-lo. Para realizar esta operação devemos substituir SEU_CÓDIGO por E + D[1:].__<br>\n",
    "_Parabéns, com o trecho E + D[1:] removemos o primeiro caractere do lado direito, visto que ele possui index 0. Portanto, uma das palavras geradas pela função será a correta._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando o novo corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alóigica', 'blóigica', 'clóigica', 'dlóigica', 'elóigica', 'flóigica', 'glóigica', 'hlóigica', 'ilóigica', 'jlóigica', 'klóigica', 'llóigica', 'mlóigica', 'nlóigica', 'olóigica', 'plóigica', 'qlóigica', 'rlóigica', 'slóigica', 'tlóigica', 'ulóigica', 'vlóigica', 'wlóigica', 'xlóigica', 'ylóigica', 'zlóigica', 'álóigica', 'âlóigica', 'àlóigica', 'ãlóigica', 'élóigica', 'èlóigica', 'êlóigica', 'ílóigica', 'ìlóigica', 'îlóigica', 'ólóigica', 'òlóigica', 'õlóigica', 'ôlóigica', 'úlóigica', 'ùlóigica', 'ûlóigica', 'çlóigica', 'laóigica', 'lbóigica', 'lcóigica', 'ldóigica', 'leóigica', 'lfóigica', 'lgóigica', 'lhóigica', 'lióigica', 'ljóigica', 'lkóigica', 'llóigica', 'lmóigica', 'lnóigica', 'loóigica', 'lpóigica', 'lqóigica', 'lróigica', 'lsóigica', 'ltóigica', 'luóigica', 'lvóigica', 'lwóigica', 'lxóigica', 'lyóigica', 'lzóigica', 'láóigica', 'lâóigica', 'làóigica', 'lãóigica', 'léóigica', 'lèóigica', 'lêóigica', 'líóigica', 'lìóigica', 'lîóigica', 'lóóigica', 'lòóigica', 'lõóigica', 'lôóigica', 'lúóigica', 'lùóigica', 'lûóigica', 'lçóigica', 'lóaigica', 'lóbigica', 'lócigica', 'lódigica', 'lóeigica', 'lófigica', 'lógigica', 'lóhigica', 'lóiigica', 'lójigica', 'lókigica', 'lóligica', 'lómigica', 'lónigica', 'lóoigica', 'lópigica', 'lóqigica', 'lórigica', 'lósigica', 'lótigica', 'lóuigica', 'lóvigica', 'lówigica', 'lóxigica', 'lóyigica', 'lózigica', 'lóáigica', 'lóâigica', 'lóàigica', 'lóãigica', 'lóéigica', 'lóèigica', 'lóêigica', 'lóíigica', 'lóìigica', 'lóîigica', 'lóóigica', 'lóòigica', 'lóõigica', 'lóôigica', 'lóúigica', 'lóùigica', 'lóûigica', 'lóçigica', 'lóiagica', 'lóibgica', 'lóicgica', 'lóidgica', 'lóiegica', 'lóifgica', 'lóiggica', 'lóihgica', 'lóiigica', 'lóijgica', 'lóikgica', 'lóilgica', 'lóimgica', 'lóingica', 'lóiogica', 'lóipgica', 'lóiqgica', 'lóirgica', 'lóisgica', 'lóitgica', 'lóiugica', 'lóivgica', 'lóiwgica', 'lóixgica', 'lóiygica', 'lóizgica', 'lóiágica', 'lóiâgica', 'lóiàgica', 'lóiãgica', 'lóiégica', 'lóiègica', 'lóiêgica', 'lóiígica', 'lóiìgica', 'lóiîgica', 'lóiógica', 'lóiògica', 'lóiõgica', 'lóiôgica', 'lóiúgica', 'lóiùgica', 'lóiûgica', 'lóiçgica', 'lóigaica', 'lóigbica', 'lóigcica', 'lóigdica', 'lóigeica', 'lóigfica', 'lóiggica', 'lóighica', 'lóigiica', 'lóigjica', 'lóigkica', 'lóiglica', 'lóigmica', 'lóignica', 'lóigoica', 'lóigpica', 'lóigqica', 'lóigrica', 'lóigsica', 'lóigtica', 'lóiguica', 'lóigvica', 'lóigwica', 'lóigxica', 'lóigyica', 'lóigzica', 'lóigáica', 'lóigâica', 'lóigàica', 'lóigãica', 'lóigéica', 'lóigèica', 'lóigêica', 'lóigíica', 'lóigìica', 'lóigîica', 'lóigóica', 'lóigòica', 'lóigõica', 'lóigôica', 'lóigúica', 'lóigùica', 'lóigûica', 'lóigçica', 'lóigiaca', 'lóigibca', 'lóigicca', 'lóigidca', 'lóigieca', 'lóigifca', 'lóigigca', 'lóigihca', 'lóigiica', 'lóigijca', 'lóigikca', 'lóigilca', 'lóigimca', 'lóiginca', 'lóigioca', 'lóigipca', 'lóigiqca', 'lóigirca', 'lóigisca', 'lóigitca', 'lóigiuca', 'lóigivca', 'lóigiwca', 'lóigixca', 'lóigiyca', 'lóigizca', 'lóigiáca', 'lóigiâca', 'lóigiàca', 'lóigiãca', 'lóigiéca', 'lóigièca', 'lóigiêca', 'lóigiíca', 'lóigiìca', 'lóigiîca', 'lóigióca', 'lóigiòca', 'lóigiõca', 'lóigiôca', 'lóigiúca', 'lóigiùca', 'lóigiûca', 'lóigiçca', 'lóigicaa', 'lóigicba', 'lóigicca', 'lóigicda', 'lóigicea', 'lóigicfa', 'lóigicga', 'lóigicha', 'lóigicia', 'lóigicja', 'lóigicka', 'lóigicla', 'lóigicma', 'lóigicna', 'lóigicoa', 'lóigicpa', 'lóigicqa', 'lóigicra', 'lóigicsa', 'lóigicta', 'lóigicua', 'lóigicva', 'lóigicwa', 'lóigicxa', 'lóigicya', 'lóigicza', 'lóigicáa', 'lóigicâa', 'lóigicàa', 'lóigicãa', 'lóigicéa', 'lóigicèa', 'lóigicêa', 'lóigicía', 'lóigicìa', 'lóigicîa', 'lóigicóa', 'lóigicòa', 'lóigicõa', 'lóigicôa', 'lóigicúa', 'lóigicùa', 'lóigicûa', 'lóigicça', 'lóigicaa', 'lóigicab', 'lóigicac', 'lóigicad', 'lóigicae', 'lóigicaf', 'lóigicag', 'lóigicah', 'lóigicai', 'lóigicaj', 'lóigicak', 'lóigical', 'lóigicam', 'lóigican', 'lóigicao', 'lóigicap', 'lóigicaq', 'lóigicar', 'lóigicas', 'lóigicat', 'lóigicau', 'lóigicav', 'lóigicaw', 'lóigicax', 'lóigicay', 'lóigicaz', 'lóigicaá', 'lóigicaâ', 'lóigicaà', 'lóigicaã', 'lóigicaé', 'lóigicaè', 'lóigicaê', 'lóigicaí', 'lóigicaì', 'lóigicaî', 'lóigicaó', 'lóigicaò', 'lóigicaõ', 'lóigicaô', 'lóigicaú', 'lóigicaù', 'lóigicaû', 'lóigicaç', 'óigica', 'ligica', 'lógica', 'lóiica', 'lóigca', 'lóigia', 'lóigic', 'lóigica']\n"
     ]
    }
   ],
   "source": [
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i],palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deletando_caractereres(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "palavra_exemplo = \"lóigica\"\n",
    "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
    "print(palavras_geradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A taxa de acerto é: 41.4% no total 186 palavras.\n"
     ]
    }
   ],
   "source": [
    "avaliador(lista_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício: Erros do correotor\n",
    "Nesta aula falamos sobre os erros relacionados a um corretor ortográfico, e vimos que eles podem estar associados a outros fatores além do algoritmo do corretor.\n",
    "\n",
    "Sobre as fontes de erro do corretor ortográfico desenvolvido, qual das alternativas é a incorreta?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) O vocabulário do corretor (palavras conhecidas por ele) também é limitante no seu desenvolvimento. Assim como os algoritmos que geram as possíveis palavras corretas, o vocabulário também contribui com o erro do corretor.<br>\n",
    "__b) Os algoritmos desenvolvidos para gerar as possíveis palavras corretas a partir de uma palavra digitada errada têm limitações, porém não são responsáveis por parte do erro do corretor, que depende apenas do vocabulário dos dados de treinamentos.__<br>\n",
    "_Parabéns, essa é realmente a alternativa incorreta. O erro associado ao corretor depende significativamente dos algoritmos que serão capazes de gerar a palavra correta._<br>\n",
    "c) Os algoritmos desenvolvidos para gerar as possíveis palavras corretas a partir de uma palavra digitada errada possuem limitações, portanto uma parte do erro está associada a esta limitação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. Corrigindo os principais erros de digitação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trocando as letras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implentando a troca de letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insere_letras(fatias):\n",
    "    novas_palavras =  []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzáâàãéèêíìîóòõôúùûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras\n",
    "\n",
    "def deletando_caractereres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(E + D[1:])\n",
    "    return novas_palavras\n",
    "    \n",
    "def troca_letra(fatias):\n",
    "    novas_palavras =  []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzáâàãéèêíìîóòõôúùûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i],palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deletando_caractereres(fatias)\n",
    "    palavras_geradas += troca_letra(fatias)\n",
    "    return palavras_geradas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alígica', 'blígica', 'clígica', 'dlígica', 'elígica', 'flígica', 'glígica', 'hlígica', 'ilígica', 'jlígica', 'klígica', 'llígica', 'mlígica', 'nlígica', 'olígica', 'plígica', 'qlígica', 'rlígica', 'slígica', 'tlígica', 'ulígica', 'vlígica', 'wlígica', 'xlígica', 'ylígica', 'zlígica', 'álígica', 'âlígica', 'àlígica', 'ãlígica', 'élígica', 'èlígica', 'êlígica', 'ílígica', 'ìlígica', 'îlígica', 'ólígica', 'òlígica', 'õlígica', 'ôlígica', 'úlígica', 'ùlígica', 'ûlígica', 'çlígica', 'laígica', 'lbígica', 'lcígica', 'ldígica', 'leígica', 'lfígica', 'lgígica', 'lhígica', 'liígica', 'ljígica', 'lkígica', 'llígica', 'lmígica', 'lnígica', 'loígica', 'lpígica', 'lqígica', 'lrígica', 'lsígica', 'ltígica', 'luígica', 'lvígica', 'lwígica', 'lxígica', 'lyígica', 'lzígica', 'láígica', 'lâígica', 'làígica', 'lãígica', 'léígica', 'lèígica', 'lêígica', 'líígica', 'lìígica', 'lîígica', 'lóígica', 'lòígica', 'lõígica', 'lôígica', 'lúígica', 'lùígica', 'lûígica', 'lçígica', 'líagica', 'líbgica', 'lícgica', 'lídgica', 'líegica', 'lífgica', 'líggica', 'líhgica', 'líigica', 'líjgica', 'líkgica', 'lílgica', 'límgica', 'língica', 'líogica', 'lípgica', 'líqgica', 'lírgica', 'lísgica', 'lítgica', 'líugica', 'lívgica', 'líwgica', 'líxgica', 'líygica', 'lízgica', 'líágica', 'líâgica', 'líàgica', 'líãgica', 'líégica', 'líègica', 'líêgica', 'líígica', 'líìgica', 'líîgica', 'líógica', 'líògica', 'líõgica', 'líôgica', 'líúgica', 'líùgica', 'líûgica', 'líçgica', 'lígaica', 'lígbica', 'lígcica', 'lígdica', 'lígeica', 'lígfica', 'líggica', 'líghica', 'lígiica', 'lígjica', 'lígkica', 'líglica', 'lígmica', 'lígnica', 'lígoica', 'lígpica', 'lígqica', 'lígrica', 'lígsica', 'lígtica', 'líguica', 'lígvica', 'lígwica', 'lígxica', 'lígyica', 'lígzica', 'lígáica', 'lígâica', 'lígàica', 'lígãica', 'lígéica', 'lígèica', 'lígêica', 'lígíica', 'lígìica', 'lígîica', 'lígóica', 'lígòica', 'lígõica', 'lígôica', 'lígúica', 'lígùica', 'lígûica', 'lígçica', 'lígiaca', 'lígibca', 'lígicca', 'lígidca', 'lígieca', 'lígifca', 'lígigca', 'lígihca', 'lígiica', 'lígijca', 'lígikca', 'lígilca', 'lígimca', 'líginca', 'lígioca', 'lígipca', 'lígiqca', 'lígirca', 'lígisca', 'lígitca', 'lígiuca', 'lígivca', 'lígiwca', 'lígixca', 'lígiyca', 'lígizca', 'lígiáca', 'lígiâca', 'lígiàca', 'lígiãca', 'lígiéca', 'lígièca', 'lígiêca', 'lígiíca', 'lígiìca', 'lígiîca', 'lígióca', 'lígiòca', 'lígiõca', 'lígiôca', 'lígiúca', 'lígiùca', 'lígiûca', 'lígiçca', 'lígicaa', 'lígicba', 'lígicca', 'lígicda', 'lígicea', 'lígicfa', 'lígicga', 'lígicha', 'lígicia', 'lígicja', 'lígicka', 'lígicla', 'lígicma', 'lígicna', 'lígicoa', 'lígicpa', 'lígicqa', 'lígicra', 'lígicsa', 'lígicta', 'lígicua', 'lígicva', 'lígicwa', 'lígicxa', 'lígicya', 'lígicza', 'lígicáa', 'lígicâa', 'lígicàa', 'lígicãa', 'lígicéa', 'lígicèa', 'lígicêa', 'lígicía', 'lígicìa', 'lígicîa', 'lígicóa', 'lígicòa', 'lígicõa', 'lígicôa', 'lígicúa', 'lígicùa', 'lígicûa', 'lígicça', 'lígicaa', 'lígicab', 'lígicac', 'lígicad', 'lígicae', 'lígicaf', 'lígicag', 'lígicah', 'lígicai', 'lígicaj', 'lígicak', 'lígical', 'lígicam', 'lígican', 'lígicao', 'lígicap', 'lígicaq', 'lígicar', 'lígicas', 'lígicat', 'lígicau', 'lígicav', 'lígicaw', 'lígicax', 'lígicay', 'lígicaz', 'lígicaá', 'lígicaâ', 'lígicaà', 'lígicaã', 'lígicaé', 'lígicaè', 'lígicaê', 'lígicaí', 'lígicaì', 'lígicaî', 'lígicaó', 'lígicaò', 'lígicaõ', 'lígicaô', 'lígicaú', 'lígicaù', 'lígicaû', 'lígicaç', 'ígica', 'lgica', 'líica', 'lígca', 'lígia', 'lígic', 'lígica', 'aígica', 'bígica', 'cígica', 'dígica', 'eígica', 'fígica', 'gígica', 'hígica', 'iígica', 'jígica', 'kígica', 'lígica', 'mígica', 'nígica', 'oígica', 'pígica', 'qígica', 'rígica', 'sígica', 'tígica', 'uígica', 'vígica', 'wígica', 'xígica', 'yígica', 'zígica', 'áígica', 'âígica', 'àígica', 'ãígica', 'éígica', 'èígica', 'êígica', 'íígica', 'ìígica', 'îígica', 'óígica', 'òígica', 'õígica', 'ôígica', 'úígica', 'ùígica', 'ûígica', 'çígica', 'lagica', 'lbgica', 'lcgica', 'ldgica', 'legica', 'lfgica', 'lggica', 'lhgica', 'ligica', 'ljgica', 'lkgica', 'llgica', 'lmgica', 'lngica', 'logica', 'lpgica', 'lqgica', 'lrgica', 'lsgica', 'ltgica', 'lugica', 'lvgica', 'lwgica', 'lxgica', 'lygica', 'lzgica', 'lágica', 'lâgica', 'làgica', 'lãgica', 'légica', 'lègica', 'lêgica', 'lígica', 'lìgica', 'lîgica', 'lógica', 'lògica', 'lõgica', 'lôgica', 'lúgica', 'lùgica', 'lûgica', 'lçgica', 'líaica', 'líbica', 'lícica', 'lídica', 'líeica', 'lífica', 'lígica', 'líhica', 'líiica', 'líjica', 'líkica', 'lílica', 'límica', 'línica', 'líoica', 'lípica', 'líqica', 'lírica', 'lísica', 'lítica', 'líuica', 'lívica', 'líwica', 'líxica', 'líyica', 'lízica', 'líáica', 'líâica', 'líàica', 'líãica', 'líéica', 'líèica', 'líêica', 'lííica', 'líìica', 'líîica', 'líóica', 'líòica', 'líõica', 'líôica', 'líúica', 'líùica', 'líûica', 'líçica', 'lígaca', 'lígbca', 'lígcca', 'lígdca', 'lígeca', 'lígfca', 'líggca', 'líghca', 'lígica', 'lígjca', 'lígkca', 'líglca', 'lígmca', 'lígnca', 'lígoca', 'lígpca', 'lígqca', 'lígrca', 'lígsca', 'lígtca', 'líguca', 'lígvca', 'lígwca', 'lígxca', 'lígyca', 'lígzca', 'lígáca', 'lígâca', 'lígàca', 'lígãca', 'lígéca', 'lígèca', 'lígêca', 'lígíca', 'lígìca', 'lígîca', 'lígóca', 'lígòca', 'lígõca', 'lígôca', 'lígúca', 'lígùca', 'lígûca', 'lígçca', 'lígiaa', 'lígiba', 'lígica', 'lígida', 'lígiea', 'lígifa', 'lígiga', 'lígiha', 'lígiia', 'lígija', 'lígika', 'lígila', 'lígima', 'lígina', 'lígioa', 'lígipa', 'lígiqa', 'lígira', 'lígisa', 'lígita', 'lígiua', 'lígiva', 'lígiwa', 'lígixa', 'lígiya', 'lígiza', 'lígiáa', 'lígiâa', 'lígiàa', 'lígiãa', 'lígiéa', 'lígièa', 'lígiêa', 'lígiía', 'lígiìa', 'lígiîa', 'lígióa', 'lígiòa', 'lígiõa', 'lígiôa', 'lígiúa', 'lígiùa', 'lígiûa', 'lígiça', 'lígica', 'lígicb', 'lígicc', 'lígicd', 'lígice', 'lígicf', 'lígicg', 'lígich', 'lígici', 'lígicj', 'lígick', 'lígicl', 'lígicm', 'lígicn', 'lígico', 'lígicp', 'lígicq', 'lígicr', 'lígics', 'lígict', 'lígicu', 'lígicv', 'lígicw', 'lígicx', 'lígicy', 'lígicz', 'lígicá', 'lígicâ', 'lígicà', 'lígicã', 'lígicé', 'lígicè', 'lígicê', 'lígicí', 'lígicì', 'lígicî', 'lígicó', 'lígicò', 'lígicõ', 'lígicô', 'lígicú', 'lígicù', 'lígicû', 'lígicç', 'lígicaa', 'lígicab', 'lígicac', 'lígicad', 'lígicae', 'lígicaf', 'lígicag', 'lígicah', 'lígicai', 'lígicaj', 'lígicak', 'lígical', 'lígicam', 'lígican', 'lígicao', 'lígicap', 'lígicaq', 'lígicar', 'lígicas', 'lígicat', 'lígicau', 'lígicav', 'lígicaw', 'lígicax', 'lígicay', 'lígicaz', 'lígicaá', 'lígicaâ', 'lígicaà', 'lígicaã', 'lígicaé', 'lígicaè', 'lígicaê', 'lígicaí', 'lígicaì', 'lígicaî', 'lígicaó', 'lígicaò', 'lígicaõ', 'lígicaô', 'lígicaú', 'lígicaù', 'lígicaû', 'lígicaç']\n"
     ]
    }
   ],
   "source": [
    "palavra_exemplo = \"lígica\"\n",
    "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
    "print(palavras_geradas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício: Trocando as letras\n",
    "Vimos que um possível erro de digitação ocorre quando sem querer trocamos as letras de uma palavra. Quando, por exemplo, digitamos \"lígica\" no lugar de \"lógica\", trocando ó por í.\n",
    "\n",
    "Selecione o código que realizará a correção para esse tipo de erro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a) def troca_letra(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzáâàãéêèẽíîìĩóôõòúûùũç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D[1:])\n",
    "    return novas_palavras__\n",
    "_Parabéns, é isso aew! Com essa função trocamos a primeira letra do lado direito da palavra, gerando a palavra correta._<br>\n",
    "b) def troca_letra(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzáâàãéêèẽíîìĩóôõòúûùũç'\n",
    "    for E, D in fatias:\n",
    "  novas_palavras.append(E + letras + D[1:])\n",
    "    return novas_palavras<br>\n",
    "c) def troca_letra(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzáâàãéêèẽíîìĩóôõòúûùũç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invertendo as letras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codando a inversão de letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverte_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        if len(D) > 1:\n",
    "            novas_palavras.append(E + D[1] + D[0] + D[2:])\n",
    "    return novas_palavras\n",
    "\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra)+1):\n",
    "        fatias.append((palavra[:i],palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deletando_caractereres(fatias)\n",
    "    palavras_geradas += troca_letra(fatias)\n",
    "    palavras_geradas +=  inverte_letras(fatias)\n",
    "    return palavras_geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algóica', 'blgóica', 'clgóica', 'dlgóica', 'elgóica', 'flgóica', 'glgóica', 'hlgóica', 'ilgóica', 'jlgóica', 'klgóica', 'llgóica', 'mlgóica', 'nlgóica', 'olgóica', 'plgóica', 'qlgóica', 'rlgóica', 'slgóica', 'tlgóica', 'ulgóica', 'vlgóica', 'wlgóica', 'xlgóica', 'ylgóica', 'zlgóica', 'álgóica', 'âlgóica', 'àlgóica', 'ãlgóica', 'élgóica', 'èlgóica', 'êlgóica', 'ílgóica', 'ìlgóica', 'îlgóica', 'ólgóica', 'òlgóica', 'õlgóica', 'ôlgóica', 'úlgóica', 'ùlgóica', 'ûlgóica', 'çlgóica', 'lagóica', 'lbgóica', 'lcgóica', 'ldgóica', 'legóica', 'lfgóica', 'lggóica', 'lhgóica', 'ligóica', 'ljgóica', 'lkgóica', 'llgóica', 'lmgóica', 'lngóica', 'logóica', 'lpgóica', 'lqgóica', 'lrgóica', 'lsgóica', 'ltgóica', 'lugóica', 'lvgóica', 'lwgóica', 'lxgóica', 'lygóica', 'lzgóica', 'lágóica', 'lâgóica', 'làgóica', 'lãgóica', 'légóica', 'lègóica', 'lêgóica', 'lígóica', 'lìgóica', 'lîgóica', 'lógóica', 'lògóica', 'lõgóica', 'lôgóica', 'lúgóica', 'lùgóica', 'lûgóica', 'lçgóica', 'lgaóica', 'lgbóica', 'lgcóica', 'lgdóica', 'lgeóica', 'lgfóica', 'lggóica', 'lghóica', 'lgióica', 'lgjóica', 'lgkóica', 'lglóica', 'lgmóica', 'lgnóica', 'lgoóica', 'lgpóica', 'lgqóica', 'lgróica', 'lgsóica', 'lgtóica', 'lguóica', 'lgvóica', 'lgwóica', 'lgxóica', 'lgyóica', 'lgzóica', 'lgáóica', 'lgâóica', 'lgàóica', 'lgãóica', 'lgéóica', 'lgèóica', 'lgêóica', 'lgíóica', 'lgìóica', 'lgîóica', 'lgóóica', 'lgòóica', 'lgõóica', 'lgôóica', 'lgúóica', 'lgùóica', 'lgûóica', 'lgçóica', 'lgóaica', 'lgóbica', 'lgócica', 'lgódica', 'lgóeica', 'lgófica', 'lgógica', 'lgóhica', 'lgóiica', 'lgójica', 'lgókica', 'lgólica', 'lgómica', 'lgónica', 'lgóoica', 'lgópica', 'lgóqica', 'lgórica', 'lgósica', 'lgótica', 'lgóuica', 'lgóvica', 'lgówica', 'lgóxica', 'lgóyica', 'lgózica', 'lgóáica', 'lgóâica', 'lgóàica', 'lgóãica', 'lgóéica', 'lgóèica', 'lgóêica', 'lgóíica', 'lgóìica', 'lgóîica', 'lgóóica', 'lgóòica', 'lgóõica', 'lgóôica', 'lgóúica', 'lgóùica', 'lgóûica', 'lgóçica', 'lgóiaca', 'lgóibca', 'lgóicca', 'lgóidca', 'lgóieca', 'lgóifca', 'lgóigca', 'lgóihca', 'lgóiica', 'lgóijca', 'lgóikca', 'lgóilca', 'lgóimca', 'lgóinca', 'lgóioca', 'lgóipca', 'lgóiqca', 'lgóirca', 'lgóisca', 'lgóitca', 'lgóiuca', 'lgóivca', 'lgóiwca', 'lgóixca', 'lgóiyca', 'lgóizca', 'lgóiáca', 'lgóiâca', 'lgóiàca', 'lgóiãca', 'lgóiéca', 'lgóièca', 'lgóiêca', 'lgóiíca', 'lgóiìca', 'lgóiîca', 'lgóióca', 'lgóiòca', 'lgóiõca', 'lgóiôca', 'lgóiúca', 'lgóiùca', 'lgóiûca', 'lgóiçca', 'lgóicaa', 'lgóicba', 'lgóicca', 'lgóicda', 'lgóicea', 'lgóicfa', 'lgóicga', 'lgóicha', 'lgóicia', 'lgóicja', 'lgóicka', 'lgóicla', 'lgóicma', 'lgóicna', 'lgóicoa', 'lgóicpa', 'lgóicqa', 'lgóicra', 'lgóicsa', 'lgóicta', 'lgóicua', 'lgóicva', 'lgóicwa', 'lgóicxa', 'lgóicya', 'lgóicza', 'lgóicáa', 'lgóicâa', 'lgóicàa', 'lgóicãa', 'lgóicéa', 'lgóicèa', 'lgóicêa', 'lgóicía', 'lgóicìa', 'lgóicîa', 'lgóicóa', 'lgóicòa', 'lgóicõa', 'lgóicôa', 'lgóicúa', 'lgóicùa', 'lgóicûa', 'lgóicça', 'lgóicaa', 'lgóicab', 'lgóicac', 'lgóicad', 'lgóicae', 'lgóicaf', 'lgóicag', 'lgóicah', 'lgóicai', 'lgóicaj', 'lgóicak', 'lgóical', 'lgóicam', 'lgóican', 'lgóicao', 'lgóicap', 'lgóicaq', 'lgóicar', 'lgóicas', 'lgóicat', 'lgóicau', 'lgóicav', 'lgóicaw', 'lgóicax', 'lgóicay', 'lgóicaz', 'lgóicaá', 'lgóicaâ', 'lgóicaà', 'lgóicaã', 'lgóicaé', 'lgóicaè', 'lgóicaê', 'lgóicaí', 'lgóicaì', 'lgóicaî', 'lgóicaó', 'lgóicaò', 'lgóicaõ', 'lgóicaô', 'lgóicaú', 'lgóicaù', 'lgóicaû', 'lgóicaç', 'góica', 'lóica', 'lgica', 'lgóca', 'lgóia', 'lgóic', 'lgóica', 'agóica', 'bgóica', 'cgóica', 'dgóica', 'egóica', 'fgóica', 'ggóica', 'hgóica', 'igóica', 'jgóica', 'kgóica', 'lgóica', 'mgóica', 'ngóica', 'ogóica', 'pgóica', 'qgóica', 'rgóica', 'sgóica', 'tgóica', 'ugóica', 'vgóica', 'wgóica', 'xgóica', 'ygóica', 'zgóica', 'ágóica', 'âgóica', 'àgóica', 'ãgóica', 'égóica', 'ègóica', 'êgóica', 'ígóica', 'ìgóica', 'îgóica', 'ógóica', 'ògóica', 'õgóica', 'ôgóica', 'úgóica', 'ùgóica', 'ûgóica', 'çgóica', 'laóica', 'lbóica', 'lcóica', 'ldóica', 'leóica', 'lfóica', 'lgóica', 'lhóica', 'lióica', 'ljóica', 'lkóica', 'llóica', 'lmóica', 'lnóica', 'loóica', 'lpóica', 'lqóica', 'lróica', 'lsóica', 'ltóica', 'luóica', 'lvóica', 'lwóica', 'lxóica', 'lyóica', 'lzóica', 'láóica', 'lâóica', 'làóica', 'lãóica', 'léóica', 'lèóica', 'lêóica', 'líóica', 'lìóica', 'lîóica', 'lóóica', 'lòóica', 'lõóica', 'lôóica', 'lúóica', 'lùóica', 'lûóica', 'lçóica', 'lgaica', 'lgbica', 'lgcica', 'lgdica', 'lgeica', 'lgfica', 'lggica', 'lghica', 'lgiica', 'lgjica', 'lgkica', 'lglica', 'lgmica', 'lgnica', 'lgoica', 'lgpica', 'lgqica', 'lgrica', 'lgsica', 'lgtica', 'lguica', 'lgvica', 'lgwica', 'lgxica', 'lgyica', 'lgzica', 'lgáica', 'lgâica', 'lgàica', 'lgãica', 'lgéica', 'lgèica', 'lgêica', 'lgíica', 'lgìica', 'lgîica', 'lgóica', 'lgòica', 'lgõica', 'lgôica', 'lgúica', 'lgùica', 'lgûica', 'lgçica', 'lgóaca', 'lgóbca', 'lgócca', 'lgódca', 'lgóeca', 'lgófca', 'lgógca', 'lgóhca', 'lgóica', 'lgójca', 'lgókca', 'lgólca', 'lgómca', 'lgónca', 'lgóoca', 'lgópca', 'lgóqca', 'lgórca', 'lgósca', 'lgótca', 'lgóuca', 'lgóvca', 'lgówca', 'lgóxca', 'lgóyca', 'lgózca', 'lgóáca', 'lgóâca', 'lgóàca', 'lgóãca', 'lgóéca', 'lgóèca', 'lgóêca', 'lgóíca', 'lgóìca', 'lgóîca', 'lgóóca', 'lgóòca', 'lgóõca', 'lgóôca', 'lgóúca', 'lgóùca', 'lgóûca', 'lgóçca', 'lgóiaa', 'lgóiba', 'lgóica', 'lgóida', 'lgóiea', 'lgóifa', 'lgóiga', 'lgóiha', 'lgóiia', 'lgóija', 'lgóika', 'lgóila', 'lgóima', 'lgóina', 'lgóioa', 'lgóipa', 'lgóiqa', 'lgóira', 'lgóisa', 'lgóita', 'lgóiua', 'lgóiva', 'lgóiwa', 'lgóixa', 'lgóiya', 'lgóiza', 'lgóiáa', 'lgóiâa', 'lgóiàa', 'lgóiãa', 'lgóiéa', 'lgóièa', 'lgóiêa', 'lgóiía', 'lgóiìa', 'lgóiîa', 'lgóióa', 'lgóiòa', 'lgóiõa', 'lgóiôa', 'lgóiúa', 'lgóiùa', 'lgóiûa', 'lgóiça', 'lgóica', 'lgóicb', 'lgóicc', 'lgóicd', 'lgóice', 'lgóicf', 'lgóicg', 'lgóich', 'lgóici', 'lgóicj', 'lgóick', 'lgóicl', 'lgóicm', 'lgóicn', 'lgóico', 'lgóicp', 'lgóicq', 'lgóicr', 'lgóics', 'lgóict', 'lgóicu', 'lgóicv', 'lgóicw', 'lgóicx', 'lgóicy', 'lgóicz', 'lgóicá', 'lgóicâ', 'lgóicà', 'lgóicã', 'lgóicé', 'lgóicè', 'lgóicê', 'lgóicí', 'lgóicì', 'lgóicî', 'lgóicó', 'lgóicò', 'lgóicõ', 'lgóicô', 'lgóicú', 'lgóicù', 'lgóicû', 'lgóicç', 'lgóicaa', 'lgóicab', 'lgóicac', 'lgóicad', 'lgóicae', 'lgóicaf', 'lgóicag', 'lgóicah', 'lgóicai', 'lgóicaj', 'lgóicak', 'lgóical', 'lgóicam', 'lgóican', 'lgóicao', 'lgóicap', 'lgóicaq', 'lgóicar', 'lgóicas', 'lgóicat', 'lgóicau', 'lgóicav', 'lgóicaw', 'lgóicax', 'lgóicay', 'lgóicaz', 'lgóicaá', 'lgóicaâ', 'lgóicaà', 'lgóicaã', 'lgóicaé', 'lgóicaè', 'lgóicaê', 'lgóicaí', 'lgóicaì', 'lgóicaî', 'lgóicaó', 'lgóicaò', 'lgóicaõ', 'lgóicaô', 'lgóicaú', 'lgóicaù', 'lgóicaû', 'lgóicaç', 'glóica', 'lógica', 'lgióca', 'lgócia', 'lgóiac']\n"
     ]
    }
   ],
   "source": [
    "palavra_exemplo = \"lgóica\"\n",
    "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
    "print(palavras_geradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "avaliador() missing 1 required positional argument: 'vocabulario'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\vinicius.barbosa\\OneDrive - Univesp Acadêmico\\Ciência de Dados\\Cursos\\cursos_data_science\\202201-ALURA-Formacao_Python_para_Data_Science\\202203-ALURA-08_09-Corretor_ortografico_em_python-Aplicanto_tecnicas_de_NLP\\nlp.ipynb Cell 92'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/vinicius.barbosa/OneDrive%20-%20Univesp%20Acad%C3%AAmico/Ci%C3%AAncia%20de%20Dados/Cursos/cursos_data_science/202201-ALURA-Formacao_Python_para_Data_Science/202203-ALURA-08_09-Corretor_ortografico_em_python-Aplicanto_tecnicas_de_NLP/nlp.ipynb#ch0000091?line=0'>1</a>\u001b[0m avaliador(lista_teste)\n",
      "\u001b[1;31mTypeError\u001b[0m: avaliador() missing 1 required positional argument: 'vocabulario'"
     ]
    }
   ],
   "source": [
    "avaliador(lista_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. Criando um corretor turbinado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Palavras desconhecidas ao vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A taxa de acerto é: 76.34% no total 186 palavras.\n",
      "A taxa desconhecida é: 6.99%.\n"
     ]
    }
   ],
   "source": [
    "def avaliador(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "        else:\n",
    "            desconhecida += (correta not in vocabulario)\n",
    "    taxa_acerto = round(acertou*100 / numero_palavras, 2)\n",
    "    taxa_desconhecida  = round(desconhecida*100 / numero_palavras, 2)\n",
    "    print(f\"A taxa de acerto é: {taxa_acerto}% no total {numero_palavras} palavras.\\nA taxa desconhecida é: {taxa_desconhecida}%.\")\n",
    "\n",
    "vocabulario = set(lista_normalizada)\n",
    "avaliador(lista_teste, vocabulario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turbinando o gerador de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavra = \"lóiigica\"\n",
    "\n",
    "def gerador_turbinado(palavras_geradas):\n",
    "    novas_palavras = []\n",
    "    for palavra in palavras_geradas:\n",
    "        novas_palavras += gerador_palavras(palavra)\n",
    "    return novas_palavras\n",
    "\n",
    "palavras_g = gerador_turbinado(gerador_palavras(palavra))\n",
    "\"lógica\" in palavras_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "691744"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(palavras_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escolhendo os melhores candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def novo_corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavras_turbinado = gerador_turbinado(palavras_geradas)\n",
    "    todas_palavras = set(palavras_geradas + palavras_turbinado)\n",
    "    candidatos = [palavra]\n",
    "    for palavra in todas_palavras:\n",
    "        if palavra in vocabulario:\n",
    "            candidatos.append(palavra)\n",
    "    #print(f'O tamanho da minha palavra candidata é : {len(candidatos)}')\n",
    "    palavra_correta = max(candidatos,key=probabilidade)\n",
    "    return palavra_correta\n",
    "\n",
    "novo_corretor(palavra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício: Distância entre palavras\n",
    "Desenvolvemos um novo corretor, com o objetivo de ser mais abrangente e corrigir palavras como lóiigica. Observe que sem querer acabamos digitando dois is. Discutimos em aula o conceito de distância entre a palavra correta e aquela digitada de maneira equivocada.\n",
    "\n",
    "Temos que a palavra correta é lógica, porém digitamos lígicaaa. Qual a distância entre estas palavras?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Dois<br>\n",
    "__b) Três__<br>\n",
    "_Parabéns, é isso mesmo. A distância entre as palavras está relacionada com a quantidade de operações que precisamos realizar para corrigir uma palavra. Neste caso precisamos trocar a letra í** por **ó e depois remover duas vezes a letra a do final._<br>\n",
    "c) Um"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. Avaliando e interpretando o erro do corretor turbinado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando o resultado dos dois corretores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A taxa de acerto é: 55.38% no total 186 palavras.\n",
      "A taxa desconhecida é: 6.99%.\n"
     ]
    }
   ],
   "source": [
    "def avaliador(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = novo_corretor(errada)\n",
    "        desconhecida += (correta not in vocabulario)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "    taxa_acerto = round(acertou*100 / numero_palavras, 2)\n",
    "    taxa_desconhecida  = round(desconhecida*100 / numero_palavras, 2)\n",
    "    print(f\"A taxa de acerto é: {taxa_acerto}% no total {numero_palavras} palavras.\\nA taxa desconhecida é: {taxa_desconhecida}%.\")\n",
    "\n",
    "vocabulario = set(lista_normalizada)\n",
    "avaliador(lista_teste, vocabulario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando o resultado dos dois corretores cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esje-esse-se\n",
      "sãêo-são-não\n",
      "dosa-dos-do\n",
      "eme-em-de\n",
      "eàssa-essa-esse\n",
      "daõs-das-da\n",
      "céda-cada-da\n",
      "noâ-no-o\n",
      "enêão-então-não\n",
      "tĩem-tem-em\n",
      "nossah-nossa-nosso\n",
      "teb-tem-de\n",
      "atĩ-até-a\n",
      "âem-em-de\n",
      "foo-foi-o\n",
      "serr-ser-se\n",
      "entke-entre-então\n",
      "van-vai-a\n",
      "çeus-seus-seu\n",
      "eû-e-de\n",
      "temeo-tempo-temos\n",
      "semre-sempre-ser\n",
      "elaá-ela-ele\n",
      "síó-só-se\n",
      "siàe-site-se\n",
      "seém-sem-em\n",
      "peln-pelo-ele\n",
      "aléra-alura-agora\n",
      "tdia-dia-da\n",
      "tuúo-tudo-tipo\n",
      "jé-é-de\n",
      "sãô-são-não\n",
      "odos-dos-do\n",
      "siua-sua-seu\n",
      "elpe-ele-esse\n",
      "teos-temos-os\n",
      "eũsa-essa-esse\n",
      "vjmos-vamos-temos\n",
      "dms-dos-de\n",
      "cava-java-para\n",
      "ános-nos-no\n",
      "èaso-caso-as\n",
      "túem-tem-em\n",
      "daáos-dados-dos\n",
      "nossk-nosso-nosso\n",
      "tãer-ter-ser\n",
      "vté-até-é\n",
      "búm-bem-um\n",
      "sçerá-será-ser\n",
      "entró-entre-então\n",
      "uai-vai-a\n",
      "sâus-seus-seu\n",
      "ìeu-seu-de\n",
      "fual-qual-sua\n",
      "elal-ela-ele\n",
      "skó-só-se\n",
      "secm-sem-em\n",
      "aluéa-alura-além\n",
      "dil-dia-de\n",
      "sód-só-se\n",
      "eúaa-aeúaa-essa\n",
      "ró-só-de\n",
      "dĩaz-adĩaz-da\n",
      "correptor-corretor-correto\n",
      "trtica-tática-prática\n",
      "ewpoderamento-aewpoderamento-ewpoderamento\n",
      "îgato-gato-fato\n",
      "cakvalo-acakvalo-carvalho\n",
      "canelac-acanelac-janela\n",
      "tênisy-atênisy-tênisy\n",
      "anciosa-aanciosa-ansioso\n",
      "ancciosa-aancciosa-ancciosa\n",
      "ansioa-aansioa-antiga\n",
      "asterístico-aasterístico-asterístico\n",
      "entertido-aentertido-entendido\n",
      "ritimo-ritmo-ótimo\n",
      "indiota-aindiota-indica\n",
      "tomare-tomar-tomar\n",
      "seje-seja-se\n",
      "provalecer-aprovalecer-prevalece\n",
      "esteje-esteja-este\n",
      "mindigo-amindigo-indico\n",
      "pertubar-apertubar-derrubar\n",
      "A taxa de acerto é: 55.38% no total 186 palavras.\n",
      "A taxa desconhecida é: 6.99%.\n"
     ]
    }
   ],
   "source": [
    "def avaliador(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = novo_corretor(errada)\n",
    "        desconhecida += (correta not in vocabulario)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "        else:\n",
    "            print(errada + \"-\" + corretor(errada) + \"-\" + palavra_corrigida)\n",
    "    taxa_acerto = round(acertou*100 / numero_palavras, 2)\n",
    "    taxa_desconhecida  = round(desconhecida*100 / numero_palavras, 2)\n",
    "    print(f\"A taxa de acerto é: {taxa_acerto}% no total {numero_palavras} palavras.\\nA taxa desconhecida é: {taxa_desconhecida}%.\")\n",
    "\n",
    "vocabulario = set(lista_normalizada)\n",
    "avaliador(lista_teste, vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A taxa de acerto é: 76.34% no total 186 palavras.\n",
      "A taxa desconhecida é: 6.99%.\n"
     ]
    }
   ],
   "source": [
    "def avaliador(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        desconhecida += (correta not in vocabulario)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "    taxa_acerto = round(acertou*100 / numero_palavras, 2)\n",
    "    taxa_desconhecida  = round(desconhecida*100 / numero_palavras, 2)\n",
    "    print(f\"A taxa de acerto é: {taxa_acerto}% no total {numero_palavras} palavras.\\nA taxa desconhecida é: {taxa_desconhecida}%.\")\n",
    "\n",
    "vocabulario = set(lista_normalizada)\n",
    "avaliador(lista_teste, vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fica\n",
      "lógica\n"
     ]
    }
   ],
   "source": [
    "palavra = \"lgica\"\n",
    "print(novo_corretor(palavra))\n",
    "print(corretor(palavra))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício: Erros do corretor turbinado\n",
    "Nesta aula foi avaliado o resultado do corretor turbinado, e discutimos sobre os motivos dele ter quebrado as expectativas de melhora. Com esta discussão em mente, responda:\n",
    "\n",
    "Qual das alternativas é a incorreta?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "a) Um dos erros do corretor turbinado se associa ao fato dele gerar tanto a possível palavra correta quanto uma variação existente no vocabulário, que apresente maior frequência.<br>\n",
    "b) Um dos erros associados ao corretor turbinado é a restrição imposta pelo vocabulário do corretor.<br>\n",
    "__c) O erro do corretor turbinado se deve ao fato dos dados de teste conter muitas palavras erradas, com distância maior, igual ou maior que 3, pois ele corrige palavras com distância de no máximo 2.__<br>\n",
    "_Parabéns, essa é realmente a alternativa incorreta. A grande maioria dos erros de digitação está a uma operação de distância da palavra correta, e nossos dados de teste tentam representar essa realidade._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7bf4cbbe7418c4c5904c81a1f330c06b14f1c71217d7fe69c29f2d1792cbbe13"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('env_cursos')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
